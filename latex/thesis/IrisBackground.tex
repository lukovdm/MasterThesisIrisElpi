\documentclass[thesis.tex]{subfiles}

\ifSubfilesClassLoaded{
  \externaldocument{thesis}
  \setcounter{chapter}{1}
}{}

\begin{document}

\chapter{Background on separation logic}
\label{ch:backgroundseplogic}

In this chapter we give a background on separation logic by specifying and proving the correctness of a program on marked linked lists (MLLs), as seen in \cref*{ch:introduction}. First we will set up the example we will discuss in this chapter in \cref*{sec:irissetup}. Next, we will be looking at separation logic as we will use it in the rest of this thesis in \cref*{sec:seplogic}. Then, we show how to give specifications using Hoare triples and weakest preconditions in \cref*{sec:Hoare}. In \cref*{sec:nestedhoaretriple} we will show how Hoare triples and weakest preconditions relate to one another and in the progress explain persistent propositions. Next, we will show how we can create a predicate used to represent a data structure for our example in \cref*{sec:represpreds}. Lastly, we will finish the specification and proof of a program manipulating marked linked lists in \cref*{sec:proofmll}.

\section{Setup}
\label{sec:irissetup}
We will be defining a program that deletes an element at an index in a MLL as our example for this chapter. This program is written in HeapLang, a higher order, untyped, ML-like language. HeapLang supports many concepts around both concurrency and higher-order heaps (storing closures on the heap), however, we won't need any of these features. It can thus be treated as a basic ML-like language. The syntax can be found in \cref*{fig:heaplangsyntax}. For more information about HeapLang one can reference the Iris technical reference \cite*{iristeamIrisReference2023}.

We make use of a few pieces of syntactic sugar to simplify notation. We write let statements, $\Let \lvar = \expr in \expr'$, using rec expressions $(\Lam \lvar. \expr')(\expr)$. To sequence expressions we write $\expr; \expr'$ which is defined using a let where we ignore the result of the first expression. The keywords $\None$ and $\Some$ are just $\Inl$ and $\Inr$ respectively, both in values and in the match statement. We define the short circuit and $\expr_1 \&\& \expr_2$ using the following if statement, $\If \expr_1 then \expr_2 \Else \False$. Lastly we omit the

\begin{figure}[ht]
  \begin{center}
    \begin{align*}
      \val,\valB \in \Val \bnfdef{} &
      z \mid
      \True \mid \False \mid
      \TT \mid
      \loc \mid                     \hspace*{2cm} (z \in \integer, \loc \in \Loc)                     \\ &
      (\val,\valB) \mid
      \Inl(\val) \mid
      \Inr(\val) \mid                                                                                 \\ &
      \Rec\lvarF\,(\lvar)= \expr                                                                      \\
      \expr \in \Expr \bnfdef{}     &
      \val \mid
      \lvar \mid
      \expr_1(\expr_2) \mid
      {}
      \HLOp_1 \expr \mid
      \expr_1 \HLOp_2 \expr_2 \mid                                                                    \\ &
      \Rec\lvarF\,(\lvar)= \expr \mid
      \If \expr then \expr_1 \Else \expr_2 \mid
      {}                                                                                              \\ &
      (\expr_1,\expr_2) \mid
      \Fst(\expr) \mid
      \Snd(\expr) \mid
      {}                                                                                              \\ &
      \Inl(\expr) \mid
      \Inr(\expr) \mid                                                                                \\ &
      \Match \expr with \Inl(\lvar) => \expr_1 | \Inr(\lvarB) => \expr_2 end \mid
      {}                                                                                              \\ &
      \Alloc(\expr) \mid
      \deref \expr \mid
      \expr_1 \gets \expr_2                                                                           \\
      \HLOp_1 \bnfdef{}             & - \mid \ldots ~~\text{(list incomplete)}                        \\
      \HLOp_2 \bnfdef{}             & + \mid - \mid \mathop{=} \mid \ldots ~~\text{(list incomplete)}
    \end{align*}
    \caption{Fragment of the syntax of HeapLang as used in the examples}
    \label{fig:heaplangsyntax}
  \end{center}
\end{figure}

The program we will be using as an example will delete an index out of the list by marking that node, thus logically deleting it.
\MLLDeleteProg
The program is a function called $\textlog{delete}$, the function has two arguments. The first argument $\loc$ is either $\None$, for the empty list, or $\Some \langv{hd}$ where $\langv{hd}$ is a pointer to a MLL. HeapLang has no null pointers, thus we use $\None$ as the null pointer. The second argument is the index in the MLL to delete. The first step this recursive function does in check whether the list we are deleting from is empty or not. We thus match $\loc$ on either $\None$, the MLL is empty, or on $\Some\,\langv{hd}$, where $\langv{hd}$ becomes the pointer to the MLL and the MLL contains some nodes. If the list is empty, we are done and return unit. If the list is not empty, we load the first node and save it in the three variables $\lvar$, $\langv{mark}$ and $\langv{tl}$. Now, $\lvar$ contains the first element of the list, $\langv{mark}$ tells us whether the element is marked, thus logically deleted, and $\langv{tl}$ contains the reference to the tail of the list. We now have three different options for our list.
\begin{itemize}
  \item If our index is zero and the element is not marked, thus logically deleted, we want to delete it. We write to the $\langv{hd}$ pointer our node, but with the mark bit set to $\True$, thus logically deleting it.
  \item If the mark bit is $\False$, but the index to delete, $\iindex$, is not zero. The current node has not been deleted, and thus we want to decrease $\iindex$ by one and recursively call our function $\operatorname{f}$ on the tail of the list.
  \item Lastly if the mark bit is set to $\True$, we want to ignore this node and continue to the next one. We thus call our recursive function $\operatorname{f}$ without decreasing $\iindex$.
\end{itemize}
$\MLLdelete\, \loc\, 1$ will thus apply the transformation below.
\begin{center}
  \begin{tikzpicture}
    \begin{scope}
      \node [MLL] (x0) at (0,0) {$\val_0$};
      \node [MLL, marked] (x1) at (3,0) {$\val_1$};
      \node [MLL] (x2) at (6,0) {$\val_2$};
      \node [MLL, null] (x3) at (9,0) {$\val_3$};

      \path[{Circle}->,thick] ([yshift=1pt,xshift=1pt]x0.three) edge [bend left] (x1.west);
      \path[{Circle}->,thick] ([yshift=1pt,xshift=1pt]x1.three) edge [bend left] (x2.west);
      \path[{Circle}->,thick] ([yshift=1pt,xshift=1pt]x2.three) edge [bend left] (x3.west);

      \node (l) [above=of x0.west] {$\loc$};
      \path[->,thick] (l) edge ([yshift=.1cm]x0.north west);
    \end{scope}
    \path[->,thick] (4.5,-1) edge[double,double distance=2pt] node[right] {$\MLLdelete\, \loc\, 1$} (4.5,-2);
    \begin{scope}[yshift=-3cm]
      \node [MLL] (x0) at (0,0) {$\val_0$};
      \node [MLL, marked] (x1) at (3,0) {$\val_1$};
      \node [MLL, marked] (x2) at (6,0) {$\val_2$};
      \node [MLL, null] (x3) at (9,0) {$\val_3$};

      \path[p->,thick] ([yshift=1pt,xshift=1pt]x0.three) edge [bend left] (x1.west);
      \path[p->,thick] ([yshift=1pt,xshift=1pt]x1.three) edge [bend left] (x2.west);
      \path[p->,thick] ([yshift=1pt,xshift=1pt]x2.three) edge [bend left] (x3.west);

      \node (l) [above=of x0.west] {$\loc$};
      \path[->,thick] (l) edge ([yshift=.1cm]x0.north west);
    \end{scope}
  \end{tikzpicture}
\end{center}
A tuple is shown here as three boxes next to each other, the first box contains a value. The second box is a boolean, it is true, thus marked, if it is crossed out. The third box is a pointer, denoted by either a cross, a null pointer, or a circle with an arrow pointing to the next node.

When thinking about it in terms of lists, $\MLLdelete\, \loc\, 1$ deletes from the list $[\val_0, \val_2, \val_3]$ the element $\val_2$, thus resulting in the list $[\val_0, \val_3]$.
In the next section we will show how separation logic can be used to reason about sections of memory, such as shown above.

\section{Separation logic}
\label{sec:seplogic}
Separation logic, \cite*{ishtiaqBIAssertionLanguage2001,reynoldsSeparationLogicLogic2002}, is a logic that allows us to represent the state of memory in a higher order predicate logic. We also make use of recent additions to separation logic as seen in ?\quest{Where do wp and persistent come frome?}. We take a subset of features from these separation logics and present them below, starting with the syntax.
\begin{align*}
  \prop \in \iProp \bnfdef{} & \FALSE \mid \TRUE \mid \prop \land \prop \mid \prop \lor \prop \mid \prop \Ra \prop \mid \Exists \var:\type. \prop \mid \All \var:\type. \prop \mid \\
                             & \pure{\pprop} \mid \loc \fmapsto \val \mid \prop * \prop \mid \prop \wand \prop \mid \always\prop \mid \wpre\expr{\pred}
\end{align*}
Separation logic contains all the usual higher order predicate logic connectives as seen on the first line, where $\type$ is any type we have seen. The second row contains separation logic specific connectives. The first connective embeds any \coq proposition, also called a pure proposition, into separation logic. \coq propositions include common connectives like equality, list manipulations and set manipulations. Whenever from context it is clear a statement is pure, we may omit the pure brackets. The next two connectives will be discussed in this section. The last three connectives will be discussed when they become relevant in \cref*{sec:Hoare} and \cref*{sec:nestedhoaretriple}. We will sometimes contract the $\wpre\expr{\pred}$ statement, and we will also discuss these contractions in \cref*{sec:Hoare}.

The first connective to discuss is the points to, $\loc\fmapsto\val$. The statement $\loc\fmapsto\val$ holds for any state of memory in which we own a location $\loc$ and at this location $\loc$ we have the value $\val$. We represent this state of memory using the below diagram.
\begin{center}
  \begin{tikzpicture}
    \node[memnode] (x) at (0,0) {$\val$};
    \node (l) [above=of x.west] {$\loc$};

    \path[->, thick] (l) edge ([yshift=.1cm]x.north west);
    % \node (logic) at (3,0.8) {$\loc\fmapsto\val$};
  \end{tikzpicture}
\end{center}
To describe two values in memory we could try to write $\loc\fmapsto\val \land \locB\fmapsto\valB$. However, this does not ensure that $\loc$ and $\locB$ are not the same location. The above diagram would still be a valid state of memory for the statement $\loc\fmapsto\val \land \locB\fmapsto\valB$. Thus, we introduce a second form of conjunction, the separating conjunction, $\prop * \propB$. For $\prop * \propB$ to hold we have to split the memory in two disjunct parts, $\prop$ should hold for one part and $\propB$ should hold for the other part.
\begin{center}
  \begin{tikzpicture}
    \node[memnode] (x) at (0,0) {$\val$};
    \node (l) [above=of x.west] {$\loc$};

    \path[->, thick] (l) edge ([yshift=.1cm]x.north west);
    \path (0.5,-.8) edge[dashed] node[fill=white] {\large$*$} (0.5,1.8);
    \begin{scope}[xshift=1.2cm]
      \node[memnode] (y) at (0,0) {$\valB$};
      \node (k) [above=of y.west] {$\locB$};

      \path[->, thick] (k) edge ([yshift=.1cm]y.north west);
    \end{scope}
    \node (logic) at (4,0.8) {$\loc\fmapsto\val\ ∗\ \locB\fmapsto\valB$};
  \end{tikzpicture}
\end{center}
The separating conjunction is formally defined by a set of rules.
\begin{mathpar}
  \begin{array}{rMcMl}
    \TRUE * \prop             & \provesIff & \prop                     \\
    \prop * \propB            & \proves    & \propB * \prop            \\
    (\prop * \propB) * \propC & \proves    & \prop * (\propB * \propC)
  \end{array}
  \and
  \inferhref{$*$-mono}{sep-mono}
  {\prop_1 \proves \propB_1 \and
    \prop_2 \proves \propB_2}
  {\prop_1 * \prop_2 \proves \propB_1 * \propB_2}
\end{mathpar}
These rules mirror the rules for the normal conjunction, however, there is one omission. We can not duplicate a proposition using the separating conjunction. Thus, the following rule is missing $\prop \proves \prop * \prop$. This makes sense intuitively since if $\loc\fmapsto\val$ holds, we could not split the memory in two, such that $\loc\fmapsto\val * \loc\fmapsto\val$ holds. We cannot have two disjunct sections of memory where $\loc$ resides in both.

\section{Writing specifications of programs}
\label{sec:Hoare}
The goal in specifying programs is to connect the world in which the program lives to the mathematical world. In the mathematical world we are able to create proofs and by linking the world of the program to the mathematical world we can prove properties of the program.

In this section we will discuss how to specify actions of a program, we will do so using two different methods, the Hoare triple and the weakest precondition. In the next section, \cref*{sec:nestedhoaretriple}, we will discuss how they are related. We will use $\MLLdelete$ as defined in \cref*{sec:irissetup} as an example throughout this section.

\paragraph{Hoare triples}
Our goal when we specify a program will be total correctness. Thus, given some precondition holds, the program does not crash and terminates and afterwards the postcondition holds. To do this we first use total Hoare triples, abbreviated to Hoare triples in this thesis.
\[\hoare{\prop}{\expr}{\pred}\]
The Hoare triple consists of three parts, the precondition, $\prop$, the expression, $\expr$, and the postcondition, $\pred$. This Hoare triple states that, given that $\prop$ holds beforehand, $\expr$ does not crash and terminates with a return value $\val$ and $\pred(\val)$ holds afterwards. Thus $\pred$ is a predicate taking a value as its argument. Whenever we write out the predicate, we omit the $\lambda$ and write $\hoare{\prop}{\expr}{\Ret\val. \propB}$ instead. Whenever we assume $\val$ to be a certain value, $\val'$, instead of writing $\hoare{\prop}\expr{\Ret\val. \val = \val' * \propB}$ we just write $\hoare{\prop}\expr{\Ret\val'. \propB}$. Lastly, if we assume the return value is the unit, $\TT$, we leave it out entirely. Thus, $\hoare{\prop}\expr{\Ret\val. \val = \TT * \propB}$ is equivalent to $\hoare{\prop}\expr{\propB}$. This will often happen as quite a few programs return $\TT$. We can now look at an example of a specification for a very simple program.
\begin{align*}
  \hoare{\loc\fmapsto\val}{\loc\gets\valB}{\loc\fmapsto\valB}
\end{align*}
This program assigns to location $\loc$ the value $\valB$. Our specification states that as a precondition, $\loc\fmapsto\val$, thus, there we own a location $\loc$, and it has value $\val$. Next, we can execute $\loc\gets\valB$, and it won't crash and will terminate. The program will return $\TT$ and afterwards $\loc\fmapsto\valB$ holds. Thus, we still own $\loc$ and it now points to the value $\valB$. The specification for $\MLLdelete$ follows the same principle.
\begin{align*}
  \hoare{\isMLL\, \langv{hd}\, \vect{\val}}{\MLLdelete\, \langv{hd}\; \iindex }{\isMLL\, \langv{hd}\; (\textlog{remove}\, \iindex\, \vect{\val})}
\end{align*}
We make use of a predicate we will explain in \cref*{sec:represpreds}. The predicate $\isMLL\, \langv{hd}\, \vect{\val}$ holds if the MLL starting at $\langv{hd}$ contains the mathematical list $\vect{\val}$. The function $\textlog{remove}$ gives the list $\vect{\val}$ with index $\iindex$ removed. If the index is larger than the size of the list the original list is returned. We thus specify the program by relating its actions to operations on a mathematical list.

\paragraph{Weakest precondition}
Hoare triples allow us to easily specify a program, however, in a proof, they can be harder to work with in conjuction with predicates like $\isMLL$. Instead, we introduce the total weakest precondition, $\wpre{\expr}{\pred}$, also abbreviated to weakest precondition from now on. The weakest precondition can be seen as a hoare triple without its precondition. Thus, $\wpre{\expr}{\pred}$ states that $\expr$ does not crash and terminates with a return value $\val$. Afterwards, $\pred(\val)$ holds. We make use of the same contractions when writing the predicate of the weakest precondition as with the Hoare triple.

We still need a concept of a precondition when working with the specification of a program, but we embed this in the logic using the magic wand.
$$\prop \wand \wpre{\expr}{\pred}$$
The magic wand acts like the normal implication while taking into account the distribution of sections of memory. The statement, $\propB \wand \propC$, describes the state of memory where if we add the memory described by $\propB$ we get $\propC$. This property is expressed by the below rule.
\begin{mathpar}
  \inferhrefB{$\wand$I-E}{wand-IE}
  {\prop * \propB \proves \propC}
  {\prop \proves \propB \wand \propC}
\end{mathpar}
Note that this is both the elimination and introduction rule, as signified by the double lined rule.

We can now rewrite the specification of $\loc\gets\val$ using the weakest precondition.
$$\loc\fmapsto\val \wand \wpre{\loc\gets\valB}{\loc\fmapsto\valB}$$
To prove that this specification holds we use the rules for the weakest precondition in \cref*{fig:wp-rules}. We can use the \ruleref{wp-store} rule to prove that the specification holds. We have two categories of rules, rules for the language constructs, such as \ruleref{wp-store}, and rules for reasoning about the structure of the language.

For reasoning about the language constructs we have three rules for the three different operations that deal with the memory and one rule for all pure operation.
\begin{itemize}
  \item The rule \ruleref{wp-alloc} defines that for $\wpre{\Alloc(\val)}{\pred}$ to hold, $\pred(\loc)$ should hold for a new $\loc$ for which we know that $\loc\fmapsto\val$.
  \item The rule \ruleref{wp-load} defines that for $\wpre{\deref \loc}{\pred}$ to hold, we need $\loc$ to point to $\val$ and separately if we add $\loc\fmapsto\val$, $\pred(\val)$ holds. Note that we need to add $\loc\fmapsto\val$ with the wand to the predicate since the statement is not duplicable. Thus, if we know $\loc\fmapsto\val$, we have to use it to prove the first part of the \ruleref{wp-load} rule. But, at this point we lose that $\loc\fmapsto\val$. Thus, the \ruleref{wp-load} rule adds that we know $\loc\fmapsto\val$ using the magic wand to the postcondition.
  \item The rule \ruleref{wp-store} works similar to \ruleref{wp-load}, but changes the value stored in $\loc$ for the postcondition.
  \item The rule \ruleref{wp-pure} defines that for any pure step we just change the expression in the weakest precondition
\end{itemize}
For reasoning about the general structure of the language and the weakest precondition itselef we also have four rules.
\begin{itemize}
  \item The rule \ruleref{wp-value} defines that if the expression is just a value, we can evaluate the postcondition.
  \item The rule \ruleref{wp-mono} allows for changing the postcondition as long as this change holds for any value.
  \item The rule \ruleref{wp-frame} allows for adding any propositions we have as assumption into the postcondition of a weakest precondition we have as assumption.
  \item The rule \ruleref{wp-bind} allows for extracting the expressions that is in the head position of a program. This is done by using contexts as defined at the bottom of \cref*{fig:wp-rules}. The verification of the rest of the program is delayed by moving it into the postcondition of the head expression.
\end{itemize}
An example where some of these rules can be found in \cref*{sec:nestedhoaretriple} and \cref*{sec:proofmll}
\begin{figure}[H]
  Structural rules.
  \begin{mathpar}
    \inferH{wp-value}
    {}{\pred(\val) \proves \wpre{\val}{\pred}}

    \inferH{wp-mono}
    {\forall v. \Phi(v) \proves \Psi(v)}
    {\wpre{e}{\Phi} \proves \wpre{e}{\Psi}}

    \inferH{wp-frame}
    {}{\propB * \wpre\expr{\Ret\var.\prop} \proves \wpre\expr{\Ret\var.\propB*\prop}}

    \inferH{wp-bind}
    {}
    {\wpre\expr{\Ret\var. \wpre{\lctx[\var]}{\pred}} \proves \wpre{\lctx[\expr]}{\pred}}
  \end{mathpar}
  Rules for basic language constructs.
  \begin{mathpar}
    \inferH{wp-alloc}
    { }
    {\All \loc. \loc \fmapsto \val \wand {\pred(\loc)} \proves \wpre{\Alloc(\val)}{\pred}}
    \and
    \inferH{wp-load}
    { }
    {\loc \fmapsto \val *\loc \fmapsto \val \wand \pred(\val)\proves \wpre{\deref \loc}{\pred}}
    \and
    \inferH{wp-store}
    { }
    {\loc \fmapsto \val * (\loc \fmapsto \valB \wand \pred\TT) \proves \wpre{(\loc \gets \valB)}{\pred}}
    \and
    \inferH{wp-pure}
    {\expr \purered \expr'}
    {\wpre{\expr'}{\pred} \proves \wpre{\expr}{\pred}}
  \end{mathpar}
  Pure reductions.
  \begin{mathpar}
    (\textlog{f}\,\lvar := \expr) \val \purered \expr[\val/\lvar][\textlog{f}\,\lvar := \expr/\textlog{f}]
    \and
    \If\True then \expr_1 \Else \expr_2 \purered \expr_1
    \and
    \If\False then \expr_1 \Else \expr_2 \purered \expr_2
    \and
    \Fst(\val_1,\val_2) \purered \val_1
    \and
    \Snd(\val_1,\val_2) \purered \val_2
    \and
    \infer
    {\HLOp_1 \val = \valB}
    {\HLOp_1 \val \purered \valB}
    \and
    \infer
    {\val_1 \HLOp_2 \val_2 = \val_3}
    {\val_1 \HLOp_2 \val_2 \purered \val_3}
    \and
    \Match\Inl\val with \Inl\lvar => \expr_1 | \Inr\lvar => \expr_2 end \purered \expr_1[\val/\lvar]
    \and
    \Match\Inr\val with \Inl\lvar => \expr_1 | \Inr\lvar => \expr_2 end \purered \expr_2[\val/\lvar]
  \end{mathpar}
  Context rules
  \begin{align*}
    \lctx \in \Lctx \bnfdef{} &
    \bullet \mid
    \expr\, \lctx \mid
    \lctx\, \val \mid
    \HLOp_1 \lctx \mid
    \expr \HLOp_2 \lctx \mid
    \lctx \HLOp_2 \val \mid
    \If \lctx then \expr_1 \Else \expr_2 \mid
    {}                          \\ &
    (\expr, \lctx) \mid
    (\lctx, \val) \mid
    \Fst(\lctx) \mid
    \Snd(\lctx) \mid
    {}                          \\ &
    \Inl(\lctx) \mid
    \Inr(\lctx) \mid
    \Match \lctx with \Inl => \expr_1 | \Inr => \expr_2 end \mid
    {}                          \\ &
    \AllocN(\expr, \lctx) \mid
    \AllocN(\lctx, \val) \mid
    \Free(\lctx) \mid
    \deref \lctx \mid
    \expr \gets \lctx \mid
    \lctx \gets \val \mid
  \end{align*}
  \caption{Rules for the weakest precondition assertion.}
  \label{fig:wp-rules}
\end{figure}
\section{Persistent propositions and nested hoare triples}
\label{sec:nestedhoaretriple}
\quest{I am using persistent modality and persistent proposition through each other in the section, is that bad?}
In this section we will show Hoare triples are defined using the weakest precondition and in the process explain persistent propositions. We end with an example showing why hoare triples are persistent and a verification of this example.
\begin{mathpar}
  \inferH{Hoare-def}
  {}
  {\hoare{P}{e}{\pred} \eqdef \always (P \wand \wpre{e}{\pred})}
\end{mathpar}
This definition is very similar to how we used weakest preconditions with a precondition. However, we wrap our the weakest precondition with precondition in a persistence modality, $\always$.

\paragraph*{Persistent propositions}
A proposition in a persistence modality has the intuitive semantics that once it holds, it will always hold. Thus, a persistent proposition can be duplicated, as can be seen in the rule \ruleref{pers-dup} below. To prove a statement is persistent, thus that $\always\prop$ holds, we are only allowed to have persistent proposition in our assumptions, as can be seen in the rule \ruleref{pers-mono} below.
\begin{mathpar}
  \inferhref{$\always$-dup}{pers-dup}
  {}
  {\always{\prop} \provesIff \always{\prop} * \always{\prop}}

  \inferhref{$\always$-sep}{pers-sep}
  {}
  {\always{(\prop * \propB)} \provesIff \always{\prop} * \always{\propB}}

  \inferhref{$\always$-mono}{pers-mono}
  {\prop \proves \propB}
  {\always{\prop} \proves \always{\propB}}

  \inferhref{$\always$-E}{pers-elim}
  {}
  {\always\prop \proves \prop}

  \inferhref{$\always$-conj}{pers-conj}
  {}
  {\always{\prop} \land \propB \proves \always{\prop} * \propB}

  \begin{array}[c]{rMcMl}
    \pure{\pprop} & \proves & \always\pure{\pprop} \\
    \TRUE         & \proves & \always\TRUE
  \end{array}

  \begin{array}[c]{rMcMl}
    \always{\prop}            & \proves & \always\always\prop       \\
    \All x. \always{\prop}    & \proves & \always{\All x. \prop}    \\
    \always{\Exists x. \prop} & \proves & \Exists x. \always{\prop}
  \end{array}
\end{mathpar}
From the above rules we can derive the following rule for introducing persistent propositions.
\begin{align*}
  \inferhref{$\always$-I}{pers-I}
  {\always\prop \proves \propB}
  {\always{\prop} \proves \always{\propB}}
\end{align*}
We keep the fact that the assumption is persistent and thus still allow for duplicating the assumption while still removing the persistence modality around the conclusion.

\paragraph*{Nested Hoare triples} From the definition of the Hoare triple, we know that Hoare triples are persistent. This is needed since we have a higher order heap, in other words, we can store closures in memory. When we store a closure in memory we can use it multiple times and thus might need to duplicate the specification of the closure multiple times. Take the following example with its specification.
\begin{align*}
   & \operatorname{refadd}\ :=\ \Lam n. \Lam \loc. \loc \gets \deref \loc + n                                                 \\
   & \hoare{\TRUE}{\operatorname{refadd}\, n}{\Ret f. {\forall \loc.\ \hoare{\loc \fmapsto m}{f\, \loc}{\loc\fmapsto m + n}}}
\end{align*}
This program takes a value $n$ and then returns a closure which we can call with a pointer to add $n$ to the value of that pointer. The specification of $\operatorname{refadd}$ has as it's postcondition another Hoare triple for the returned closure. We just need one more derived rule before we can apply this specification of $\operatorname{refadd}$ in a proof.
\begin{mathpar}
  \inferH{wp-apply}
  {\prop \proves \hoare{\propC}{\expr}{\predB} \and \propB \proves \propC * \All \val. \predB(\val) \wand \wpre{\lctx[\val]}{\pred}}
  {\prop * \propB \proves \wpre{\lctx[\expr]}{\pred}}
\end{mathpar}
Given we need to prove a weakest precondition of an expression in a context, and we have a Hoare triple for that expression. We can apply the Hoare triple and use the postcondition to infer a value for the continued proof of the weakest precondition.
\begin{lemma}
  The below Hoare triple holds given that $$\hoare{\TRUE}{\operatorname{refadd}\, n}{\Ret f. {\forall \loc.\ \hoare{\loc \fmapsto m}{f\, \loc}{\loc\fmapsto m + n}}}$$
  \[
    \begin{aligned}
       & \rightbracket{\TRUE}                         \\
       & \quad \Let g = \operatorname{refadd}\, 10 in \\
       & \quad \Let \loc = \Alloc 0 in                \\
       & \quad g\, \loc; g\, \loc; \deref \loc        \\
       & \rightbracket{\Ret 20. \TRUE}
    \end{aligned}
  \]
\end{lemma}
\begin{proof}
  We use \ruleref{Hoare-def} and introduce the persistence modality and wand. We now need to prove the following.
  \[\wpre{
      \left(
      \begin{array}{l}
        \Let g = \operatorname{refadd}\, 10 in \\
        \Let \loc = \Alloc 0 in                \\
        g\, \loc; g\, \loc; \deref \loc
      \end{array}
      \right)
    }{\Ret 20. \TRUE}\]
  We apply the \ruleref{wp-bind} rule with the following context
  \[
    \lctx = \begin{array}{l}
      \Let g = \bullet in     \\
      \Let \loc = \Alloc 0 in \\
      g\, \loc; g\, \loc; \deref \loc
    \end{array}
  \]
  Resulting in the following weakest precondition we need to prove.
  \[
    \wpre{\operatorname{refadd}\, 10}{
      \Ret\val. \wpre{\left(\begin{array}{l}
          \Let g = \val in        \\
          \Let \loc = \Alloc 0 in \\
          g\, \loc; g\, \loc; \deref \loc
        \end{array}\right)}{\Ret 20. \True}
    }
  \]
  We now use the \ruleref{wp-apply} to get the following statement we need to prove.
  \[
    \wpre{\left(\begin{array}{l}
        \Let g = f in           \\
        \Let \loc = \Alloc 0 in \\
        g\, \loc; g\, \loc; \deref \loc
      \end{array}\right)}{\Ret 20. \True}
  \]
  With as assumption the following.
  \[
    \forall \loc.\ \hoare{\loc \fmapsto m}{f\, \loc}{\loc\fmapsto m + 10}
  \]
  Applying \ruleref{wp-pure} gets us the following statement to prove.
  \[
    \wpre{\left(\begin{array}{l}
        \Let \loc = \Alloc 0 in \\
        f\, \loc; f\, \loc; \deref \loc
      \end{array}\right)}{\Ret 20. \True}
  \]
  Using \ruleref{wp-bind} and \ruleref{wp-alloc} reaches the following statement to prove.
  \[
    \wpre{\left(\begin{array}{l}
        f\, \loc; f\, \loc; \deref \loc
      \end{array}\right)}{\Ret 20. \True}
  \]
  With as added assumption that, $\loc \fmapsto 0$ holds. We can now duplicate the Hoare triple about $f$ we have as assumption. We use \ruleref{wp-bind} with the first instance of the Hoare triple and the assumption about $\loc$ applied using \ruleref{wp-apply}. This is repeated and we reach the following prove state.
  \[
    \wpre{\deref \loc}{\Ret 20. \True}
  \]
  With as assumption that $\loc \fmapsto 20$ holds. We can now use the \ruleref{wp-load} rule to prove the statement.

\end{proof}
\section{Representation predicates}
\label{sec:represpreds}
We have shown in the previous three sections how one can represent simple states of memory in a logic and reason about it together with the program. However, this does not easily scale to more complicated data types, especially recursive data types. One such data type is the MLL. We want to connect a MLL in memory to a mathematical list. In \cref*{sec:Hoare} we used the predicate $\isMLL\, \langv{hd}\, \vect{v}$, which tells us that the in the memory starting at $\langv{hd}$ we can find a MLL that represents the list $\vect{\val}$. In the next chapter we will show how such a predicate can be made, in this section we will show how such a predicate can be used.

We start with an example of how $\isMLL$ is used.
\begin{center}
  \begin{tikzpicture}
    \begin{scope}
      \node [MLL] (x0) at (0,0) {$x_0$};
      \node [MLL, marked] (x1) at (3,0) {$x_1$};
      \node [MLL] (x2) at (6,0) {$x_2$};
      \node [MLL, null] (x3) at (9,0) {$x_3$};

      \path[{Circle}->,thick] ([yshift=1pt,xshift=1pt]x0.three) edge [bend left] (x1.west);
      \path[{Circle}->,thick] ([yshift=1pt,xshift=1pt]x1.three) edge [bend left] (x2.west);
      \path[{Circle}->,thick] ([yshift=1pt,xshift=1pt]x2.three) edge [bend left] (x3.west);

      \node (l) [above=of x0.west] {$l$};
      \path[->,thick] (l) edge ([yshift=.1cm]x0.north west);
    \end{scope}
  \end{tikzpicture}
\end{center}
We want to reason about the above state of memory. Using the predicate $\isMLL$ we state that it represents the list $[x_0, x_1, x_2]$. This is expressed as, $\isMLL\,(\Some\loc)\,[x_0,x_2,x_3]$.

To illustrate how $\isMLL$ works we give the below inductive predicate. This will not be a valid definition for $\isMLL$ for the rest of this thesis as will be made clear in \cref*{ch:fixpoints}, but it will serve as an explanation for this chapter.
\begin{align*}
  \isMLL\, \langv{hd}\, \vect{\val} & =
  \begin{array}{cl}
         & \langv{hd} = \None * \vect{\val} = []                                                                                                      \\
    \lor & \langv{hd} = \Some l * l \fmapsto (\val', \True, \langv{tl}) * \isMLL\, \langv{tl}\, \vect{\val}                                           \\
    \lor & \langv{hd} = \Some l * l \fmapsto (\val', \False, \langv{tl}) * \vect{\val} = \val' :: \vect{\val}'' * \isMLL\, \langv{tl}\, \vect{\val}''
  \end{array}
\end{align*}
The predicate \isMLL for a $\langv{hd}$ and $\vect{\val}$ holds if either of the below three options are true, as signified by the disjunction.
\begin{itemize}
  \item The $\langv{hd}$ is $\None$ and thus the mathematical list, $\vect{\val}$ is also empty
  \item The $\langv{hd}$ contains a pointer to some node, this node is marked as deleted and the tail is a MLL represented by the original list $\vect{\val}$. Note that the location $\loc$ cannot be used again in the list as it is disjunct by use of the separating conjunction.
  \item The value $\langv{hd}$ contains a pointer to some node, and this node is not marked as deleted. The list $\vect{\val}$ now starts with the value $\val'$ and ends in the list $\vect{\val}''$. Lastly, the value $\langv{tl}$ is a MLL represented by this mathematical list $\vect{\val}''$
\end{itemize}

Since $\isMLL$ is an inductive predicate we can define an induction principle. In \cref*{ch:fixpoints} we will show how this induction principle can be derived from the definition of $\isMLL$.
\begin{mathpar}
  \inferhref{\isMLL-ind}{ismll-ind}
  {\proves \pred\, \None\, []
    \\
    l \fmapsto (\val', \True, \langv{tl}) * (\isMLL\, \langv{tl}\, \vect{\val} \land \pred\, \langv{tl}\, \vect{\val}) \proves \pred\, (\Some l)\, \vect{\val}
    \\
    l \fmapsto (\val', \False, \langv{tl}) * (\isMLL\, \langv{tl}\, \vect{\val} \land \pred\, \langv{tl}\, \vect{\val}) \proves \pred\, (\Some l)\, (\val' :: \vect{\val})
  }
  {\isMLL\, \langv{hd}\, \vect{\val} \proves \pred\, \langv{hd}\, \vect{\val}}
\end{mathpar}
To use this rule we need two things. We need to have an assumption of the shape $\isMLL\, \langv{hd}\, \vect{\val}$, and we need to prove a predicate $\pred$ that takes these same $\langv{hd}$ and $\vect{\val}$ as variables. We then need to prove that $\pred$ holds for the three cases of the induction principle of $\isMLL$.
\begin{description}
  \item[Case Empty MLL:] This is the base case, we have to prove $\pred$ with $\None$ and the empty list.
  \item[Case Marked Head:] This is the first inductive case, we have to prove $\pred$ for a head containing a pointer $\loc$ and the list $\vect{\val}$. We get as assumption that $\loc$ points to a node that is marked as deleted and contains a possible null pointer $\langv{tl}$. We also get the following induction hypothesis: the tail, $\langv{tl}$, is a MLL represented by $\vect{\val}$, and $\pred$ holds for $\langv{tl}$ and $\vect{\val}$.
  \item[Case Unmarked head:] This is the second inductive case, we have to prove $\pred$ for a head containing a pointer $\loc$ and a list with as first element $\val'$ and the rest of the list is name $\vect{\val}$. We get as assumption that $\loc$ points to a node that is marked as not deleted and the node contains a possible null pointer $\langv{tl}$. We also get the following induction hypothesis: the tail, $\langv{tl}$, is a MLL represented by $\vect{\val}$, and $\pred$ holds for $\langv{tl}$ and $\vect{\val}$.
\end{description}
The induction hypothesis in the last two cases is different from statements we have seen so far in separation logic, it uses the normal conjunction. We use the normal conjunction since both $\isMLL\, \langv{tl}\, \vect{\val}$ and $\pred\, \langv{tl}\, \vect{\val}$ reason about the section of memory containing $\langv{tl}$. We thus cannot split the memory in two for these two statements. This also has a side effect on how we use the induction hypothesis. We can only use one side of the conjunction in any one branch of the proof. We will see this in practice in the next section, \cref*{sec:proofmll}.

\section{Proof of delete in MLL}
\label{sec:proofmll}
In this section we will prove the specification of $\MLLdelete$. Recall the definition of $\MLLdelete$.
\MLLDeleteProg
\\
\begin{lemma}
  For any index $i \ge 0$, list $\vect{\val}$ of values and $\langv{hd}\in\Val$,
  \[
    \hoare{\isMLL\, \langv{hd}\, \vect{\val}}{\MLLdelete\, \langv{hd}\; \iindex }{\isMLL\, \langv{hd}\; (\textlog{remove}\, \iindex\, \vect{v})}
  \]
\end{lemma}
\begin{proof}
  We first use the definition of a Hoare triple, \ruleref{Hoare-def}, to create the associated weakest precondition.
  We thus need to prove that
  \[\always(\isMLL\, \langv{hd}\, \vect{\val} \wand \wpre{\MLLdelete\, \langv{hd}\; \iindex}{\isMLL\, \langv{hd}\; (\textlog{remove}\, \iindex\, \vect{v})})\]
  Since we have only persistent assumptions we can assume
  $\isMLL\, \langv{hd}\, \vect{\val}$, and we now have to prove the following:
  \[\wpre{\MLLdelete\, \langv{hd}\; \iindex}{\isMLL\, \langv{hd}\; (\textlog{remove}\, \iindex\, \vect{v})}\]
  We do strong induction on $\isMLL\, \langv{hd}\, \vect{\val}$ as defined by rule \ruleref{ismll-ind}. For $\pred$ we take:
  \[
    \pred\, \langv{hd}\, \vect{\val} \eqdef \All \iindex. \wpre{\MLLdelete\, \langv{hd}\; \iindex}{\isMLL\, \langv{hd}\; (\textlog{remove}\, \iindex\, \vect{v})}
  \]
  And, as a result we get three cases we need to prove:
  \begin{description}
    \item[Case Empty MLL:] We need to prove the following
      \[\wpre{\MLLdelete\, \None\; \iindex}{\isMLL\, \None\; (\textlog{remove}\, \iindex\, [])}\]
      We can now repeatedly use the \ruleref{wp-pure} rule and finish with the rule \ruleref{wp-value} to arrive at the following statement that we have to prove:
      \[\isMLL\, \None\; (\textlog{remove}\, \iindex\, [])\]
      This follows from the definition of $\isMLL$
    \item[Case Marked Head:] We know that $\loc \fmapsto (\val', \True, \langv{tl})$ with disjointly as IH the following:
      \[\left(\All \iindex. \wpre{\MLLdelete\, \langv{tl}\; \iindex}{\isMLL\, \langv{tl}\; (\textlog{remove}\, \iindex\, \vect{\val})}\right) \land \isMLL\, \langv{tl}\, \vect{\val}\]
      And, we need to prove that:
      \[\wpre{\MLLdelete\, (\Some \loc)\; \iindex}{\isMLL\, (\Some \loc)\; (\textlog{remove}\, \iindex\, \vect{v})}\]
      By using the \ruleref{wp-pure} rule, we get that we need to prove:
      \[\wpre{
          \left(
          \begin{array}{l}
              \Let (\lvar, \langv{mark}, \langv{tl}) = \deref \loc in \\
              \If \langv{mark} = \False\ \&\&\ \iindex = 0 then       \\
              \quad \loc \gets (\lvar, \True, \langv{tl})             \\
              \Else \If \langv{mark} = \False then                    \\
              \quad \MLLdelete\,\langv{tl}\ (\iindex - 1)             \\
              \Else                                                   \\
              \quad \MLLdelete\,\langv{tl}\ \iindex
            \end{array}
          \right)
        }{\isMLL\, (\Some \loc)\; (\textlog{remove}\, \iindex\, \vect{v})}\]
      We can now use \ruleref{wp-bind} and \ruleref{wp-load} with $\loc \fmapsto (\val, \True, \langv{tl})$ to get our new statement that we need to prove:
      \[
        \wpre{\left(
          \begin{array}{l}
              \Let (\lvar, \langv{mark}, \langv{tl}) = (\val, \True, \langv{tl}) in \\
              \If \langv{mark} = \False\ \&\&\ \iindex = 0 then                     \\
              \quad \loc \gets (\lvar, \True, \langv{tl})                           \\
              \Else \If \langv{mark} = \False then                                  \\
              \quad \MLLdelete\,\langv{tl}\ (\iindex - 1)                           \\
              \Else                                                                 \\
              \quad \MLLdelete\,\langv{tl}\ \iindex
            \end{array}
          \right)}{\isMLL\, (\Some \loc)\; (\textlog{remove}\, \iindex\, \vect{v})}
      \]
      We now repeatedly use \ruleref{wp-pure} to reach the following:
      \[
        \wpre{\MLLdelete\,\langv{tl}\ \iindex}{\isMLL\, (\Some \loc)\; (\textlog{remove}\, \iindex\, \vect{\val})}
      \]
      Which is the left-hand side of our IH.
    \item[Case Unmarked head:] We know that $\loc \fmapsto (\val', \False, \langv{tl})$ with disjointly as IH the following:
      \[\All \iindex. \wpre{\MLLdelete\, \langv{tl}\; \iindex}{\isMLL\, \langv{tl}\; (\textlog{remove}\, \iindex\, \vect{\val}'')} \land \isMLL\, \langv{tl}\, \vect{\val}''\]
      And, we need to prove that:
      \[\wpre{\MLLdelete\, (\Some \loc)\; \iindex}{\isMLL\, (\Some \loc)\; (\textlog{remove}\, \iindex\, (\val' :: \vect{\val}''))}\]
      We repeat the steps from the previous case, except for using $\loc \fmapsto (\val, \False, \langv{tl})$ with the \ruleref{wp-load} rule, until we repeatedly use \ruleref{wp-pure}. We instead use \ruleref{wp-pure} once to reach the following statement:
      \[
        \wpre{\left(
          \begin{array}{l}
              \If \False = \False\ \&\&\ \iindex = 0 then \\
              \quad \loc \gets (\val', \True, \langv{tl}) \\
              \Else \If \False = \False then              \\
              \quad \MLLdelete\,\langv{tl}\ (\iindex - 1) \\
              \Else                                       \\
              \quad \MLLdelete\,\langv{tl}\ \iindex
            \end{array}
          \right)}{\isMLL\, (\Some \loc)\; (\textlog{remove}\, \iindex\, (\val' :: \vect{\val}''))}
      \]
      Here we do a case distinction on whether $\iindex = 0$, thus if we want to delete the current head of the MLL.
      \begin{description}
        \item[Case $i = 0$:] We repeatedly use \ruleref{wp-pure} until we reach:
          \[
            \wpre{\loc \gets (\val, \True, \langv{tl})}{\isMLL\, (\Some \loc)\; (\textlog{remove}\, 0\, (\val' :: \vect{\val}''))}
          \]
          We then use \ruleref{wp-store} with $\loc \fmapsto (\val, \True, \langv{tl})$, which we retained after the previous use of \ruleref{wp-load}, and \ruleref{wand-IE}. We now get that $\loc \fmapsto (\val', \False, \langv{tl})$, and we need to prove:
          \[
            \wpre{()}{\isMLL\, (\Some \loc)\; (\textlog{remove}\, 0\, (\val' :: \vect{\val}''))}
          \]
          We use \ruleref{wp-value} to reach:
          \[
            \isMLL\, (\Some \loc)\; (\textlog{remove}\, 0\, (\val' :: \vect{\val}''))
          \]
          This now follows from the fact that $(\textlog{remove}\, 0\, (\val' :: \vect{\val}'')) = \vect{\val}''$ together with the definition of $\isMLL$, $\loc \fmapsto (\val', \False, \langv{tl})$ and the IH.
        \item[Case $i > 0$:] We repeatedly use \ruleref{wp-pure} until we reach:
          \[
            \wpre{\MLLdelete\,\langv{tl}\ (\iindex - 1)}{\isMLL\, (\Some \loc)\; (\textlog{remove}\, (\iindex - 1)\, (\val' :: \vect{\val}''))}
          \]
          We use \ruleref{wp-mono} with as assumption our the left-hand side of the IH. We now need to prove the following:
          \[\isMLL\, \langv{tl}\; (\textlog{remove}\, \iindex\, \vect{\val}'') \proves \isMLL\, (\Some \loc)\; (\textlog{remove}\, (\iindex - 1)\, (\val' :: \vect{\val}''))\]
          This follows from the fact that $(\textlog{remove}\, (\iindex - 1)\, (\val' :: \vect{\val}'')) = \val' :: (\textlog{remove}\, \iindex\, \vect{\val}'')$ together with the definition of $\isMLL$ and $\loc \fmapsto (\val, \False, \langv{tl})$, which we retained from \ruleref{wp-load}. \qedhere
      \end{description}
  \end{description}
\end{proof}

\end{document}